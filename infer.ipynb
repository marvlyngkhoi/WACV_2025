{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_data.pkl\", \"rb\") as f:\n",
    "    test_dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "evs_path = 'weights/evs_model.pth'\n",
    "main_model_path = \"weights/main_model.pth\"\n",
    "\n",
    "\n",
    "evs = torch.load(evs_path, map_location=device)\n",
    "main_model = torch.load(main_model_path, map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, average_precision_score\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "def pad(batch, classifier=None, dim: int = 512, max_len: int = None, device=\"cpu\"):\n",
    "    if max_len is None:\n",
    "        max_len = max([len(x) for x in batch])\n",
    "    attention_mask = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(batch)):\n",
    "            ones = [0] * len(batch[i])\n",
    "            pad_length = max_len - len(batch[i])\n",
    "            if pad_length == 0:\n",
    "                attention_mask.append(ones)\n",
    "                continue\n",
    "            if classifier:\n",
    "                padding = classifier.position_embeddings(\n",
    "                    torch.ones((pad_length), dtype=torch.long, device=device)\n",
    "                    * classifier.pad_token\n",
    "                )\n",
    "            else:\n",
    "                padding = torch.zeros(pad_length, dim)\n",
    "            zeros = [1] * pad_length\n",
    "            batch[i] = torch.cat([batch[i].to(device), padding])\n",
    "            attention_mask.append(ones + zeros)\n",
    "        attention_mask = [[0] + x for x in attention_mask]\n",
    "        return torch.stack([x.to(device) for x in batch]), torch.tensor(\n",
    "            attention_mask\n",
    "        ).to(device)\n",
    "\n",
    "class Evaluate:\n",
    "    def __init__(\n",
    "        self,\n",
    "        main_model,\n",
    "        evs_model,\n",
    "        device,\n",
    "        loss_function,\n",
    "        multi_model=False,\n",
    "        batch_size=12,\n",
    "    ):\n",
    "        self.main_model = main_model.eval()\n",
    "        self.evs_model = evs_model.eval()\n",
    "        self.device = device\n",
    "        self.multi_model = multi_model\n",
    "        self.loss = loss_function\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def eval(self, dataset):\n",
    "        batch_size = self.batch_size\n",
    "        real = []\n",
    "        pred = []\n",
    "        y_scores = []\n",
    "        video_ids = []\n",
    "        losses = []\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(dataset), batch_size):\n",
    "                batch = [x[0] for x in dataset[i : i + batch_size]]\n",
    "                labels = torch.stack([x[1] for x in dataset[i : i + batch_size]])\n",
    "                video_ids.append([x[-1] for x in dataset[i : i + batch_size]])\n",
    "                audio_data = [torch.stack([y[1] for y in x]).squeeze(1) for x in batch]\n",
    "                video_data = [[y[0] for y in x] for x in batch]\n",
    "                video_data = [\n",
    "                    [torch.stack(y).squeeze(1) if type(y) is list else y for y in x]\n",
    "                    for x in video_data\n",
    "                ]\n",
    "                video_data = [\n",
    "                    self.evs_model(*pad(x, self.evs_model, device=self.device))\n",
    "                    for x in video_data\n",
    "                ]\n",
    "                video_data, v_mask = pad(\n",
    "                    video_data, self.main_model, device=self.device\n",
    "                )\n",
    "                audio_data, a_mask = pad(\n",
    "                    audio_data, self.main_model, device=self.device\n",
    "                )\n",
    "                if self.multi_model:\n",
    "                    final_data = audio_data + video_data\n",
    "                else:\n",
    "                    final_data = audio_data\n",
    "                label_output = self.main_model(final_data, attention_mask=a_mask)\n",
    "                losses.append(\n",
    "                    self.loss(label_output.view(-1, 3), labels.to(self.device).view(-1))\n",
    "                )\n",
    "                \n",
    "                # Store raw model outputs (probabilities)\n",
    "                y_scores.append(F.softmax(label_output.view(-1, 5, 3),dim=-1))#label_output.view(-1, 5, 3)\n",
    "                \n",
    "                pred.append(torch.argmax(label_output.view(-1, 5, 3), dim=-1))\n",
    "                real.append(labels)\n",
    "                \n",
    "        \n",
    "        real, pred = torch.cat(real).cpu(), torch.cat(pred).cpu() \n",
    "        y_scores = torch.cat(y_scores).cpu()  # Concatenate all y_scores\n",
    "        y_scores_aspects = y_scores[:, :, 1:].max(dim=-1).values.numpy()\n",
    "        y_scores_complaint = y_scores[:, :, 2:].max(dim=-1).values.numpy()\n",
    "        \n",
    "        return (\n",
    "            f1_score(real >= 1, pred >= 1, average=\"micro\"),\n",
    "            f1_score(real >= 2, pred >= 2, average=\"micro\"),\n",
    "            torch.mean(torch.stack(losses)).item(),\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"Video ID\": [y for x in video_ids for y in x],\n",
    "                    \"Aspects real\": (real >= 1).to(torch.long).tolist(),\n",
    "                    \"Aspects pred\": (pred >= 1).to(torch.long).tolist(),\n",
    "                    \"Complaint real\": (real >= 2).to(torch.long).tolist(),\n",
    "                    \"Complaint pred\": (pred >= 2).to(torch.long).tolist(),\n",
    "                    \"Complaint scores\":y_scores_complaint.tolist(),\n",
    "                    \"Aspects scores\":y_scores_aspects.tolist(),\n",
    "                }\n",
    "            ),\n",
    "            y_scores,  # Add y_scores to the returned tuple\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6025641025641025"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator  = Evaluate(\n",
    "    main_model, evs_model=evs, device=device, loss_function=loss_fn, multi_model=True\n",
    ")\n",
    "f1_aspect, f1_complaint, loss_cal, data, y_scores = evaluator.eval(test_dataset)\n",
    "f1_aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video ID</th>\n",
       "      <th>Aspects real</th>\n",
       "      <th>Aspects pred</th>\n",
       "      <th>Complaint real</th>\n",
       "      <th>Complaint pred</th>\n",
       "      <th>Complaint scores</th>\n",
       "      <th>Aspects scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51e4YIHE5sU.mp4</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 1, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[0.2906479835510254, 0.07512342184782028, 0.28...</td>\n",
       "      <td>[0.2906479835510254, 0.07512342184782028, 0.30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FI65fJQ6bEM.mp4</td>\n",
       "      <td>[0, 0, 0, 1, 0]</td>\n",
       "      <td>[0, 0, 0, 1, 0]</td>\n",
       "      <td>[0, 0, 0, 1, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[0.016603317111730576, 0.08133836090564728, 0....</td>\n",
       "      <td>[0.2702391743659973, 0.1317998617887497, 0.031...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1705732629717258718.mp4</td>\n",
       "      <td>[0, 0, 0, 0, 1]</td>\n",
       "      <td>[1, 0, 0, 1, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[0.08062469214200974, 0.06945031881332397, 0.0...</td>\n",
       "      <td>[0.659968376159668, 0.12646417319774628, 0.032...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1705745405131051310.mp4</td>\n",
       "      <td>[0, 0, 0, 1, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[0.014080013148486614, 0.023925885558128357, 0...</td>\n",
       "      <td>[0.02765473537147045, 0.08400814235210419, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yrgnxaAOuws.mp4</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[0.12284839898347855, 0.3853851556777954, 0.02...</td>\n",
       "      <td>[0.12284839898347855, 0.3853851556777954, 0.06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>k4gZTf2LVdU.mp4</td>\n",
       "      <td>[1, 0, 1, 1, 0]</td>\n",
       "      <td>[0, 0, 1, 1, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[0.09134558588266373, 0.019946636632084846, 0....</td>\n",
       "      <td>[0.4150772988796234, 0.11562275886535645, 0.83...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>J8-pMPud7gE.mp4</td>\n",
       "      <td>[0, 1, 1, 1, 0]</td>\n",
       "      <td>[0, 0, 1, 1, 0]</td>\n",
       "      <td>[0, 1, 0, 1, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[0.011677383445203304, 0.010007177479565144, 0...</td>\n",
       "      <td>[0.1897369623184204, 0.045635491609573364, 0.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>b6PolFcMVpI.mp4</td>\n",
       "      <td>[0, 0, 1, 1, 1]</td>\n",
       "      <td>[0, 0, 1, 1, 0]</td>\n",
       "      <td>[0, 0, 0, 1, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[0.07080940157175064, 0.05303401127457619, 0.3...</td>\n",
       "      <td>[0.3958565592765808, 0.13174274563789368, 0.51...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1468611338192797702.mp4</td>\n",
       "      <td>[0, 0, 0, 0, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 1]</td>\n",
       "      <td>[0.09551646560430527, 0.12740866839885712, 0.0...</td>\n",
       "      <td>[0.09551646560430527, 0.12740866839885712, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>lasAAAhkFb0.mp4</td>\n",
       "      <td>[1, 0, 1, 1, 0]</td>\n",
       "      <td>[1, 0, 1, 1, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[0.03979397937655449, 0.07282602787017822, 0.1...</td>\n",
       "      <td>[0.5276293158531189, 0.11175128817558289, 0.81...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Video ID     Aspects real     Aspects pred  \\\n",
       "0           51e4YIHE5sU.mp4  [0, 1, 0, 0, 0]  [0, 0, 0, 1, 0]   \n",
       "1           FI65fJQ6bEM.mp4  [0, 0, 0, 1, 0]  [0, 0, 0, 1, 0]   \n",
       "2   1705732629717258718.mp4  [0, 0, 0, 0, 1]  [1, 0, 0, 1, 0]   \n",
       "3   1705745405131051310.mp4  [0, 0, 0, 1, 0]  [0, 0, 0, 0, 0]   \n",
       "4           yrgnxaAOuws.mp4  [0, 1, 0, 0, 0]  [0, 0, 0, 0, 0]   \n",
       "..                      ...              ...              ...   \n",
       "59          k4gZTf2LVdU.mp4  [1, 0, 1, 1, 0]  [0, 0, 1, 1, 0]   \n",
       "60          J8-pMPud7gE.mp4  [0, 1, 1, 1, 0]  [0, 0, 1, 1, 0]   \n",
       "61          b6PolFcMVpI.mp4  [0, 0, 1, 1, 1]  [0, 0, 1, 1, 0]   \n",
       "62  1468611338192797702.mp4  [0, 0, 0, 0, 1]  [0, 0, 0, 0, 1]   \n",
       "63          lasAAAhkFb0.mp4  [1, 0, 1, 1, 0]  [1, 0, 1, 1, 0]   \n",
       "\n",
       "     Complaint real   Complaint pred  \\\n",
       "0   [0, 0, 0, 0, 0]  [0, 0, 0, 0, 0]   \n",
       "1   [0, 0, 0, 1, 0]  [0, 0, 0, 0, 0]   \n",
       "2   [0, 0, 0, 0, 1]  [0, 0, 0, 0, 0]   \n",
       "3   [0, 0, 0, 0, 0]  [0, 0, 0, 0, 0]   \n",
       "4   [0, 1, 0, 0, 0]  [0, 0, 0, 0, 0]   \n",
       "..              ...              ...   \n",
       "59  [0, 0, 0, 0, 0]  [0, 0, 0, 0, 0]   \n",
       "60  [0, 1, 0, 1, 0]  [0, 0, 0, 0, 0]   \n",
       "61  [0, 0, 0, 1, 0]  [0, 0, 0, 0, 0]   \n",
       "62  [0, 0, 0, 0, 1]  [0, 0, 0, 0, 1]   \n",
       "63  [0, 0, 0, 0, 0]  [0, 0, 0, 0, 0]   \n",
       "\n",
       "                                     Complaint scores  \\\n",
       "0   [0.2906479835510254, 0.07512342184782028, 0.28...   \n",
       "1   [0.016603317111730576, 0.08133836090564728, 0....   \n",
       "2   [0.08062469214200974, 0.06945031881332397, 0.0...   \n",
       "3   [0.014080013148486614, 0.023925885558128357, 0...   \n",
       "4   [0.12284839898347855, 0.3853851556777954, 0.02...   \n",
       "..                                                ...   \n",
       "59  [0.09134558588266373, 0.019946636632084846, 0....   \n",
       "60  [0.011677383445203304, 0.010007177479565144, 0...   \n",
       "61  [0.07080940157175064, 0.05303401127457619, 0.3...   \n",
       "62  [0.09551646560430527, 0.12740866839885712, 0.0...   \n",
       "63  [0.03979397937655449, 0.07282602787017822, 0.1...   \n",
       "\n",
       "                                       Aspects scores  \n",
       "0   [0.2906479835510254, 0.07512342184782028, 0.30...  \n",
       "1   [0.2702391743659973, 0.1317998617887497, 0.031...  \n",
       "2   [0.659968376159668, 0.12646417319774628, 0.032...  \n",
       "3   [0.02765473537147045, 0.08400814235210419, 0.2...  \n",
       "4   [0.12284839898347855, 0.3853851556777954, 0.06...  \n",
       "..                                                ...  \n",
       "59  [0.4150772988796234, 0.11562275886535645, 0.83...  \n",
       "60  [0.1897369623184204, 0.045635491609573364, 0.6...  \n",
       "61  [0.3958565592765808, 0.13174274563789368, 0.51...  \n",
       "62  [0.09551646560430527, 0.12740866839885712, 0.0...  \n",
       "63  [0.5276293158531189, 0.11175128817558289, 0.81...  \n",
       "\n",
       "[64 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data.copy()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Video ID', 'Aspects real_1', 'Aspects real_2', 'Aspects real_3',\n",
       "       'Aspects real_4', 'Aspects real_5', 'Aspects pred_1', 'Aspects pred_2',\n",
       "       'Aspects pred_3', 'Aspects pred_4', 'Aspects pred_5',\n",
       "       'Complaint real_1', 'Complaint real_2', 'Complaint real_3',\n",
       "       'Complaint real_4', 'Complaint real_5', 'Complaint pred_1',\n",
       "       'Complaint pred_2', 'Complaint pred_3', 'Complaint pred_4',\n",
       "       'Complaint pred_5', 'Complaint scores_1', 'Complaint scores_2',\n",
       "       'Complaint scores_3', 'Complaint scores_4', 'Complaint scores_5',\n",
       "       'Aspects scores_1', 'Aspects scores_2', 'Aspects scores_3',\n",
       "       'Aspects scores_4', 'Aspects scores_5'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    if isinstance(df[col][0], list):  # Check if column contains lists (one-hot encoded arrays)\n",
    "        expanded_array = np.array(df[col].tolist())\n",
    "        num_categories = expanded_array.shape[1]\n",
    "        category_columns = [f'{col}_{i+1}' for i in range(num_categories)]\n",
    "        df[category_columns] = pd.DataFrame(expanded_array, index=df.index)\n",
    "        df.drop(columns=[col], inplace=True)  \n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming Loss (Aspects): 0.19375\n",
      "Hamming Loss (Complaint): 0.115625\n",
      "Coverage Error (Aspect): 2.484375\n",
      "Coverage Error (Complaint): 1.171875\n",
      "Average Precision Score (Aspect): 0.5468275390329145\n",
      "Avrerage Precision Score (Complaint): 0.4113288894706388\n",
      "Ranking Loss (Aspect): 0.22526041666666669\n",
      "Ranking Loss (Complaint): 0.15104166666666666\n",
      "Micro-F1 Score (Aspects): 0.6025641025641025\n",
      "Macro-F1 Score (Aspects): 0.45386310604096447\n",
      "Micro-F1 Score (Complaint): 0.24489795918367346\n",
      "Macro-F1 Score (Complaint): 0.34523809523809523\n",
      "Accuracy (Aspect): 0.203125\n",
      "Accuracy (Complaint): 0.46875\n",
      "Zero-One Loss (Aspects): 0.796875\n",
      "Zero-One Loss (Complaint): 0.53125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import *\n",
    "# Example calculation for Hamming Loss for Aspects\n",
    "y_true_aspects = df[['Aspects real_1', 'Aspects real_2', 'Aspects real_3', 'Aspects real_4', 'Aspects real_5']].values\n",
    "y_pred_aspects = df[['Aspects pred_1', 'Aspects pred_2', 'Aspects pred_3', 'Aspects pred_4', 'Aspects pred_5']].values\n",
    "\n",
    "y_true_complaint = df[['Complaint real_1', 'Complaint real_2', 'Complaint real_3', 'Complaint real_4', 'Complaint real_5']].values\n",
    "y_pred_complaint = df[['Complaint pred_1', 'Complaint pred_2', 'Complaint pred_3', 'Complaint pred_4', 'Complaint pred_5']].values\n",
    "\n",
    "hamming_loss_aspects = hamming_loss(y_true_aspects, y_pred_aspects)\n",
    "print(f'Hamming Loss (Aspects): {hamming_loss_aspects}')\n",
    "hamming_loss_complaint = hamming_loss(y_true_complaint, y_pred_complaint)\n",
    "print(f'Hamming Loss (Complaint): {hamming_loss_complaint}')\n",
    "\n",
    "y_complaint_scores = df[['Complaint scores_1', 'Complaint scores_2', 'Complaint scores_3', 'Complaint scores_4', 'Complaint scores_5']].values\n",
    "y_aspects_scores = df[['Aspects scores_1', 'Aspects scores_2', 'Aspects scores_3', 'Aspects scores_4', 'Aspects scores_5']].values\n",
    "\n",
    "\n",
    "coverage_error_aspect = coverage_error(y_true_aspects,y_aspects_scores)\n",
    "print(f'Coverage Error (Aspect): {coverage_error_aspect}')\n",
    "coverage_error_complaint = coverage_error(y_true_complaint,y_complaint_scores)\n",
    "print(f'Coverage Error (Complaint): {coverage_error_complaint}')\n",
    "\n",
    "\n",
    "average_precision_score_aspect = average_precision_score(y_true_aspects,y_aspects_scores)\n",
    "print(f'Average Precision Score (Aspect): {average_precision_score_aspect}')\n",
    "average_precision_score_complaint =average_precision_score(y_true_complaint,y_complaint_scores)\n",
    "print(f'Avrerage Precision Score (Complaint): {average_precision_score_complaint}')\n",
    "\n",
    "\n",
    "ranking_loss_aspect = label_ranking_loss(y_true_aspects,y_aspects_scores)\n",
    "print(f'Ranking Loss (Aspect): {ranking_loss_aspect }')\n",
    "ranking_loss_complaint = label_ranking_loss(y_true_complaint,y_complaint_scores)\n",
    "print(f'Ranking Loss (Complaint): {ranking_loss_complaint}')\n",
    "\n",
    "\n",
    "micro_f1_aspects = f1_score(y_true_aspects, y_pred_aspects, average='micro')\n",
    "\n",
    "# Calculate Macro-F1 Score\n",
    "macro_f1_aspects = f1_score(y_true_aspects, y_pred_aspects, average='macro')\n",
    "\n",
    "print(f'Micro-F1 Score (Aspects): {micro_f1_aspects}')\n",
    "print(f'Macro-F1 Score (Aspects): {macro_f1_aspects}')\n",
    "\n",
    "\n",
    "micro_f1_complaint = f1_score(y_true_complaint, y_pred_complaint, average='micro')\n",
    "\n",
    "# Calculate Macro-F1 Score\n",
    "macro_f1_complaint = f1_score(y_true_complaint, y_pred_complaint, average='macro')\n",
    "\n",
    "print(f'Micro-F1 Score (Complaint): {micro_f1_complaint}')\n",
    "print(f'Macro-F1 Score (Complaint): {macro_f1_complaint}')\n",
    "\n",
    "\n",
    "print(f'Accuracy (Aspect): {accuracy_score(y_true_aspects, y_pred_aspects)}')\n",
    "print(f'Accuracy (Complaint): {accuracy_score(y_true_complaint, y_pred_complaint)}')\n",
    "\n",
    "\n",
    "zero_one_loss_aspects = zero_one_loss(y_true_aspects, y_pred_aspects)\n",
    "print(f'Zero-One Loss (Aspects): {zero_one_loss_aspects}')\n",
    "\n",
    "zero_one_loss_complaint = zero_one_loss(y_true_complaint, y_pred_complaint)\n",
    "print(f'Zero-One Loss (Complaint): {zero_one_loss_complaint}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics Results for Aspects:\n",
      "Aspect_1:\n",
      "\tHamming Loss: 0.234375\n",
      "\tAccuracy: 0.765625\n",
      "\tAverage Precision Score: 0.34822315018292777\n",
      "\tZero-One Loss: 0.234375\n",
      "\tMicro-F1 Score: 0.765625\n",
      "\tMacro-F1 Score: 0.5727636849132176\n",
      "Aspect_2:\n",
      "\tHamming Loss: 0.1875\n",
      "\tAccuracy: 0.8125\n",
      "\tAverage Precision Score: 0.19883875318027003\n",
      "\tZero-One Loss: 0.1875\n",
      "\tMicro-F1 Score: 0.8125\n",
      "\tMacro-F1 Score: 0.518796992481203\n",
      "Aspect_3:\n",
      "\tHamming Loss: 0.078125\n",
      "\tAccuracy: 0.921875\n",
      "\tAverage Precision Score: 0.8668977592768867\n",
      "\tZero-One Loss: 0.078125\n",
      "\tMicro-F1 Score: 0.921875\n",
      "\tMacro-F1 Score: 0.8885405781957506\n",
      "Aspect_4:\n",
      "\tHamming Loss: 0.28125\n",
      "\tAccuracy: 0.71875\n",
      "\tAverage Precision Score: 0.8367561235511078\n",
      "\tZero-One Loss: 0.28125\n",
      "\tMicro-F1 Score: 0.71875\n",
      "\tMacro-F1 Score: 0.708502024291498\n",
      "Aspect_5:\n",
      "\tHamming Loss: 0.1875\n",
      "\tAccuracy: 0.8125\n",
      "\tAverage Precision Score: 0.4834219089733796\n",
      "\tZero-One Loss: 0.1875\n",
      "\tMicro-F1 Score: 0.8125\n",
      "\tMacro-F1 Score: 0.5714285714285714\n",
      "\n",
      "Metrics Results for Complaint:\n",
      "Complaint_1:\n",
      "\tHamming Loss: 0.0625\n",
      "\tAccuracy: 0.9375\n",
      "\tAverage Precision Score: 0.15705576265921092\n",
      "\tZero-One Loss: 0.0625\n",
      "\tMicro-F1 Score: 0.9375\n",
      "\tMacro-F1 Score: 0.4838709677419355\n",
      "Complaint_2:\n",
      "\tHamming Loss: 0.09375\n",
      "\tAccuracy: 0.90625\n",
      "\tAverage Precision Score: 0.17941288839575967\n",
      "\tZero-One Loss: 0.09375\n",
      "\tMicro-F1 Score: 0.90625\n",
      "\tMacro-F1 Score: 0.6\n",
      "Complaint_3:\n",
      "\tHamming Loss: 0.0\n",
      "\tAccuracy: 1.0\n",
      "\tAverage Precision Score: 1.0\n",
      "\tZero-One Loss: 0.0\n",
      "\tMicro-F1 Score: 1.0\n",
      "\tMacro-F1 Score: 1.0\n",
      "Complaint_4:\n",
      "\tHamming Loss: 0.265625\n",
      "\tAccuracy: 0.734375\n",
      "\tAverage Precision Score: 0.24068958075937624\n",
      "\tZero-One Loss: 0.265625\n",
      "\tMicro-F1 Score: 0.734375\n",
      "\tMacro-F1 Score: 0.5157988429016467\n",
      "Complaint_5:\n",
      "\tHamming Loss: 0.15625\n",
      "\tAccuracy: 0.84375\n",
      "\tAverage Precision Score: 0.47948621553884707\n",
      "\tZero-One Loss: 0.15625\n",
      "\tMicro-F1 Score: 0.84375\n",
      "\tMacro-F1 Score: 0.5989974937343359\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store results\n",
    "metrics_results_aspects = {}\n",
    "metrics_results_complaint = {}\n",
    "\n",
    "# Calculate metrics for Aspects columns\n",
    "for i in range(1, 6):\n",
    "    y_true_aspects = df[f'Aspects real_{i}'].values\n",
    "    y_pred_aspects = df[f'Aspects pred_{i}'].values\n",
    "    y_aspects_scores = df[f'Aspects scores_{i}'].values\n",
    "    \n",
    "    hamming_loss_aspect = hamming_loss(y_true_aspects, y_pred_aspects)\n",
    "    #coverage_error_aspect = coverage_error(y_true_aspects, y_aspects_scores)\n",
    "    average_precision_score_aspect = average_precision_score(y_true_aspects, y_aspects_scores)\n",
    "    #ranking_loss_aspect = label_ranking_loss(y_true_aspects, y_aspects_scores)\n",
    "    micro_f1_aspect = f1_score(y_true_aspects, y_pred_aspects, average='micro')\n",
    "    macro_f1_aspect = f1_score(y_true_aspects, y_pred_aspects, average='macro')\n",
    "    \n",
    "    metrics_results_aspects[f'Aspect_{i}'] = {\n",
    "        'Hamming Loss': hamming_loss_aspect,\n",
    "        'Accuracy':accuracy_score(y_true_aspects, y_pred_aspects),\n",
    "        'Average Precision Score': average_precision_score_aspect,\n",
    "        'Zero-One Loss':zero_one_loss(y_true_aspects, y_pred_aspects),\n",
    "        'Micro-F1 Score': micro_f1_aspect,\n",
    "        'Macro-F1 Score': macro_f1_aspect\n",
    "    }\n",
    "\n",
    "# Calculate metrics for Complaint columns\n",
    "for i in range(1, 6):\n",
    "    y_true_complaint = df[f'Complaint real_{i}'].values\n",
    "    y_pred_complaint = df[f'Complaint pred_{i}'].values\n",
    "    y_complaint_scores = df[f'Complaint scores_{i}'].values\n",
    "    \n",
    "    hamming_loss_complaint = hamming_loss(y_true_complaint, y_pred_complaint)\n",
    "    #coverage_error_complaint = coverage_error(y_true_complaint, y_complaint_scores)\n",
    "    average_precision_score_complaint = average_precision_score(y_true_complaint, y_complaint_scores)\n",
    "    #ranking_loss_complaint = label_ranking_loss(y_true_complaint, y_complaint_scores)\n",
    "    micro_f1_complaint = f1_score(y_true_complaint, y_pred_complaint, average='micro')\n",
    "    macro_f1_complaint = f1_score(y_true_complaint, y_pred_complaint, average='macro')\n",
    "    \n",
    "    metrics_results_complaint[f'Complaint_{i}'] = {\n",
    "        'Hamming Loss': hamming_loss_complaint,\n",
    "        'Accuracy':accuracy_score(y_true_complaint, y_pred_complaint),\n",
    "        'Average Precision Score': average_precision_score_complaint,\n",
    "        'Zero-One Loss':zero_one_loss(y_true_complaint, y_pred_complaint),\n",
    "        'Micro-F1 Score': micro_f1_complaint,\n",
    "        'Macro-F1 Score': macro_f1_complaint\n",
    "    }\n",
    "\n",
    "# Print results for Aspects\n",
    "print(\"Metrics Results for Aspects:\")\n",
    "for aspect, metrics in metrics_results_aspects.items():\n",
    "    print(f\"{aspect}:\")\n",
    "    for metric_name, value in metrics.items():\n",
    "        print(f\"\\t{metric_name}: {value}\")\n",
    "\n",
    "# Print results for Complaint\n",
    "print(\"\\nMetrics Results for Complaint:\")\n",
    "for complaint, metrics in metrics_results_complaint.items():\n",
    "    print(f\"{complaint}:\")\n",
    "    for metric_name, value in metrics.items():\n",
    "        print(f\"\\t{metric_name}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mtp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
